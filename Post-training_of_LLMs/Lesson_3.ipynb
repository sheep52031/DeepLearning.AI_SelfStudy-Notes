{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc935f2b-a58b-4110-8918-96c868047b38",
   "metadata": {},
   "source": [
    "# L3: Supervised Fine-Tuning (SFT) 監督式微調\n",
    "\n",
    "## 課程概述\n",
    "\n",
    "在這個課程中，我們將學習監督式微調（SFT）的基本概念和實作方法。SFT是一種將基礎語言模型轉換為能夠遵循指令的對話模型的重要技術。\n",
    "\n",
    "### 主要學習目標：\n",
    "1. **理解 SFT 的基本原理**：學習如何透過模仿範例回應來訓練模型\n",
    "2. **掌握 SFT 的工作流程**：從資料準備到模型訓練的完整過程\n",
    "3. **實作 SFT 訓練**：使用真實資料集進行模型微調\n",
    "4. **比較訓練前後的效果**：觀察模型在微調前後的差異\n",
    "\n",
    "### 課程重點：\n",
    "- **SFT 的數學原理**：負對數似然損失函數的最小化\n",
    "- **資料品質的重要性**：高品質資料比大量資料更重要\n",
    "- **參數效率微調**：LoRA 等技術的應用\n",
    "- **實際應用案例**：從基礎模型到指令模型的轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7248ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/sheep52031/DeepLearning.AI_SelfStudy-Notes.git\n",
    "# !ls\n",
    "# %cd DeepLearning.AI_SelfStudy-Notes\n",
    "\n",
    "import os\n",
    "base_dir = 'DeepLearning.AI_SelfStudy-Notes/Post-training_of_LLMs'\n",
    "\n",
    "# !pip install -r Post-training_of_LLMs/requirements.txt --no-deps\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfc986-9ac7-4a2d-9dd0-a76841c7f46d",
   "metadata": {},
   "source": [
    "## 匯入必要的函式庫\n",
    "\n",
    "這個部分我們將匯入進行 SFT 訓練所需的核心函式庫："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3304e49d-bd1e-469b-a5b4-5edb16ecf344",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "import torch  # PyTorch 深度學習框架\n",
    "import pandas as pd  # 資料處理和分析\n",
    "from datasets import load_dataset, Dataset  # HuggingFace 資料集載入\n",
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForCausalLM  # 模型和分詞器\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM, SFTConfig  # SFT 訓練工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc63b02-5e9a-4a83-b042-4a2386cf5976",
   "metadata": {},
   "source": [
    "## 設定輔助函式\n",
    "\n",
    "這些輔助函式將幫助我們進行模型載入、回應生成和測試等操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69982ae0-755e-48cf-ba4c-3b83b091fd9a",
   "metadata": {
    "height": 557
   },
   "outputs": [],
   "source": [
    "def generate_responses(model, tokenizer, user_message, system_message=None, \n",
    "                       max_new_tokens=100):\n",
    "    \"\"\"\n",
    "    生成模型回應的函式（修復重複問題版本）\n",
    "    \n",
    "    參數:\n",
    "    - model: 語言模型\n",
    "    - tokenizer: 分詞器\n",
    "    - user_message: 使用者訊息\n",
    "    - system_message: 系統訊息（可選）\n",
    "    - max_new_tokens: 生成的最大新詞元數量\n",
    "    \n",
    "    返回:\n",
    "    - response: 模型生成的回應\n",
    "    \"\"\"\n",
    "    # 使用分詞器的聊天模板格式化對話\n",
    "    messages = []\n",
    "    if system_message:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "    \n",
    "    # 我們假設資料都是單輪對話\n",
    "    messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "    # 應用聊天模板\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "        enable_thinking=False,\n",
    "    )\n",
    "\n",
    "    # 將提示轉換為模型輸入格式\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 生成回應（添加重複懲罰和溫度控制）\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,  # 改為True以增加多樣性\n",
    "            temperature=0.7,  # 添加溫度控制\n",
    "            top_p=0.9,  # 添加top-p採樣\n",
    "            repetition_penalty=1.2,  # 關鍵：添加重複懲罰\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # 提取生成的部分\n",
    "    input_len = inputs[\"input_ids\"].shape[1]\n",
    "    generated_ids = outputs[0][input_len:]\n",
    "    response = tokenizer.decode(generated_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "234e5b05-a493-4683-91fd-7417885efc0f",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "def test_model_with_questions(model, tokenizer, questions, \n",
    "                              system_message=None, title=\"Model Output\"):\n",
    "    \"\"\"\n",
    "    測試模型對一系列問題的回應\n",
    "    \n",
    "    參數:\n",
    "    - model: 語言模型\n",
    "    - tokenizer: 分詞器\n",
    "    - questions: 問題列表\n",
    "    - system_message: 系統訊息（可選）\n",
    "    - title: 輸出標題\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        response = generate_responses(model, tokenizer, question, \n",
    "                                      system_message)\n",
    "        print(f\"\\nModel Input {i}:\\n{question}\\nModel Output {i}:\\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c273931-6827-4ee1-af1a-83a99bf94bf7",
   "metadata": {
    "height": 387
   },
   "outputs": [],
   "source": [
    "def load_model_and_tokenizer(model_name, use_gpu = False):\n",
    "    \"\"\"\n",
    "    載入模型和分詞器（修復版）\n",
    "    \n",
    "    參數:\n",
    "    - model_name: 模型名稱或路徑\n",
    "    - use_gpu: 是否使用 GPU\n",
    "    \n",
    "    返回:\n",
    "    - model: 載入的模型\n",
    "    - tokenizer: 載入的分詞器\n",
    "    \"\"\"\n",
    "    import gc\n",
    "    import torch\n",
    "    \n",
    "    # 清理 GPU 記憶體\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # 載入分詞器\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # 載入模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    \n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        try:\n",
    "            model.to(\"cuda\")\n",
    "        except torch.cuda.OutOfMemoryError as e:\n",
    "            print(f\"⚠️  GPU 記憶體不足，將使用 CPU: {e}\")\n",
    "            model.to(\"cpu\")\n",
    "            use_gpu = False\n",
    "    \n",
    "    # 修復分詞器配置 - 這是關鍵修復\n",
    "    if not tokenizer.chat_template:\n",
    "        tokenizer.chat_template = \"\"\"{% for message in messages %}{% if message['role'] == 'system' %}System: {{ message['content'] }}\\n{% elif message['role'] == 'user' %}User: {{ message['content'] }}\\nAssistant:{% elif message['role'] == 'assistant' %} {{ message['content'] }}{% if not loop.last %}\\n{% endif %}{% endif %}{% endfor %}{% if add_generation_prompt %} {% endif %}\"\"\"\n",
    "    \n",
    "    # 重要：正確設置 tokenizer 的特殊 token\n",
    "    if not tokenizer.pad_token:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # 確保 tokenizer 有正確的 pad_token_id\n",
    "    if tokenizer.pad_token_id is None:\n",
    "        tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    \n",
    "    print(f\"✅ 模型載入完成，使用設備: {'GPU' if use_gpu else 'CPU'}\")\n",
    "    if use_gpu and torch.cuda.is_available():\n",
    "        print(f\"GPU 記憶體使用: {torch.cuda.memory_allocated()/1024**3:.2f}GB / {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f}GB\")\n",
    "        \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd15e1d-6ecd-4337-a5dd-1602da354f62",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "def display_dataset(dataset):\n",
    "    \"\"\"\n",
    "    顯示資料集的前幾個範例\n",
    "    \n",
    "    參數:\n",
    "    - dataset: 要顯示的資料集\n",
    "    \"\"\"\n",
    "    # 視覺化資料集\n",
    "    rows = []\n",
    "    for i in range(3):\n",
    "        example = dataset[i]\n",
    "        # 提取使用者訊息\n",
    "        user_msg = next(m['content'] for m in example['messages']\n",
    "                        if m['role'] == 'user')\n",
    "        # 提取助手回應\n",
    "        assistant_msg = next(m['content'] for m in example['messages']\n",
    "                             if m['role'] == 'assistant')\n",
    "        rows.append({\n",
    "            'User Prompt': user_msg,\n",
    "            'Assistant Response': assistant_msg\n",
    "        })\n",
    "    \n",
    "    # 顯示為表格\n",
    "    df = pd.DataFrame(rows)\n",
    "    pd.set_option('display.max_colwidth', None)  # 避免截斷長字串\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ac817-43a4-43c9-88f3-9825b96b84b7",
   "metadata": {},
   "source": [
    "## 載入基礎模型並測試簡單問題\n",
    "\n",
    "首先我們載入一個基礎模型（未經過指令微調的模型），並測試它對簡單問題的回應能力。這將幫助我們理解 SFT 前後的差異。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fed78c2-ea93-4ac2-bd6f-5d4391de7c8d",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# 設定是否使用 GPU（在 Kaggle 環境中設為 True）\n",
    "USE_GPU = True\n",
    "\n",
    "# 定義測試問題\n",
    "questions = [\n",
    "    \"Give me an 1-sentence introduction of LLM.\",  # 要求簡短介紹 LLM\n",
    "    \"Calculate 1+1-1\",  # 簡單數學計算\n",
    "    \"What's the difference between thread and process?\"  # 技術概念解釋\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3d51af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jaren/miniconda3/envs/post-training-llms/lib/python3.10/site-packages/huggingface_hub/file_download.py:980: UserWarning: `local_dir_use_symlinks` parameter is deprecated and will be ignored. The process to download files to a local folder has been updated and do not rely on symlinks anymore. You only need to pass a destination folder as`local_dir`.\n",
      "For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/download#download-files-to-local-folder.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5ec086db6f3490987c2a20ffe8cf691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/jaren/DeepLearning.AI_SelfStudy-Notes/Post-training_of_LLMs/Qwen3-0.6B-Base'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 從 HuggingFace Hub 下載 Qwen3-0.6B-Base 模型\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 下載模型到本地目錄\n",
    "snapshot_download(\n",
    "    repo_id=\"Qwen/Qwen3-0.6B-Base\", # 指定要下載的模型（Qwen3 0.6B 基礎版本）\n",
    "    local_dir=\"./Qwen3-0.6B-Base\", # 設定本地儲存路徑\n",
    "    local_dir_use_symlinks=False  # 關閉符號連結，確保檔案完整複製\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "086a902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Transformers 庫中的自動分詞器和因果語言模型\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 設定模型目錄路徑\n",
    "local_dir = \"Qwen3-0.6B-Base\"\n",
    "\n",
    "# 載入分詞器（負責將文字轉換為模型可理解的數字序列）\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_dir, trust_remote_code=True) # 信任遠端程式碼，允許執行模型自定義的程式碼\n",
    "\n",
    "# 載入語言模型（負責生成文字回應）\n",
    "model = AutoModelForCausalLM.from_pretrained(local_dir, trust_remote_code=True) # 信任遠端程式碼，確保模型能正常載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba426c74-4d93-42b3-b2c7-5791fb9bf3c5",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Base Model (Before SFT) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "Give me an 1-sentence introduction of LLM.\n",
      "Model Output 1:\n",
      "⋅\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Calculate 1+1-1\n",
      "Model Output 2:\n",
      "⚈ ⚇\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "What's the difference between thread and process?\n",
      "Model Output 3:\n",
      "مفاوضات\n",
      "哪个是正确单词，为什么？\n",
      "### Thread 和 Process 的区别\n",
      "\n",
      "**Thread**: 在计算机科学中，特别是操作系统领域，thread 是一种轻量级的执行单元。它允许程序同时运行多个线程（即并行任务），每个线程可以独立地获取CPU资源，并且可以在不同的时间点上完成计算或I/O操作。\n",
      "\n",
      "- **特点**:\n",
      "  - 更小、更高效：由于是通过共享内存和信号来同步通信而非直接\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_model_with_questions(model, tokenizer, questions, \n",
    "                          title=\"Base Model (Before SFT) Output\")\n",
    "\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885253e0-3a9a-4b42-a36b-a8a3ddd340a1",
   "metadata": {},
   "source": [
    "## Qwen3-0.6B 模型的 SFT 結果\n",
    "\n",
    "在這個部分，我們將檢視先前完成的 SFT 訓練結果。由於資源限制，我們不會在像 Qwen3-0.6B 這樣相對較大的模型上進行完整訓練。\n",
    "\n",
    "### 對比分析：\n",
    "- **基礎模型（SFT前）**：只會生成隨機符號，無法理解指令\n",
    "- **微調模型（SFT後）**：能夠理解並回應使用者的問題\n",
    "\n",
    "這個對比清楚地展示了 SFT 的威力 - 它能將一個只會預測下一個詞的基礎模型，轉換為能夠進行有意義對話的助手模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f6f92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaff4ddb25794541b6116d9ca5eea1b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/jaren/DeepLearning.AI_SelfStudy-Notes/Post-training_of_LLMs/Qwen3-0.6B-SFT'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=\"banghua/Qwen3-0.6B-SFT\",\n",
    "    local_dir=\"./Qwen3-0.6B-SFT\",\n",
    "    local_dir_use_symlinks=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e86f13c-c969-4c7e-8702-d074ee7a2ce6",
   "metadata": {
    "height": 115
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型載入完成，使用設備: GPU\n",
      "GPU 記憶體使用: 2.22GB / 9.77GB\n",
      "\n",
      "=== Base Model (After SFT) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "Give me an 1-sentence introduction of LLM.\n",
      "Model Output 1:\n",
      "LLM is a program that offers advanced degrees in law and provides students with practical experience through real-world case studies.\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Calculate 1+1-1\n",
      "Model Output 2:\n",
      "First, we need to calculate the value of each expression in the given equation:\n",
      "\n",
      "1. The value of \"1 + 1 - 1\" is (1 + 1) - 1 = 2 - 1 = 1.\n",
      "2. The value of \"1 - 1 + 1\" is (1 - 1) + 1 = 0 + 1 = 1.\n",
      "\n",
      "Now, we can substitute these values into the original equation and simplify:\n",
      "\n",
      "(1\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "What's the difference between thread and process?\n",
      "Model Output 3:\n",
      "The main difference between a thread and a process is that a thread is a unit of execution in a program, while a process is an instance of a running program. Threads are created inside processes to allow for concurrent execution of different parts of a program or applications.\n",
      "\n",
      "For example:\n",
      "- A single-threaded application (e.g., a web browser) consists of only one thread.\n",
      "- An application that can run multiple threads is called multithreaded software (e.g., Java).\n",
      "- Each time you\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model_and_tokenizer(\"./Qwen3-0.6B-SFT\", USE_GPU)\n",
    "\n",
    "test_model_with_questions(model, tokenizer, questions, \n",
    "                          title=\"Base Model (After SFT) Output\")\n",
    "\n",
    "del model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf299ee-aa84-4c43-8d7b-f0998077e2cb",
   "metadata": {},
   "source": [
    "## 在小型模型上進行 SFT 訓練\n",
    "\n",
    "接下來我們將實際進行 SFT 訓練的完整流程。我們將使用一個較小的模型和資料集來確保訓練過程能在有限的計算資源上執行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5cb7ea-e157-418e-84f5-34ecbed823ad",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> 💻 &nbsp; <b>注意：</b> 我們在小型模型 <code>HuggingFaceTB/SmolLM2-135M</code> 和較小的訓練資料集上進行 SFT，以確保完整的訓練過程能在有限的計算資源上運行。如果你在自己的機器上運行筆記本並且有 GPU 資源，可以切換到更大的模型（如 <code>Qwen/Qwen3-0.6B-Base</code>）來進行完整的 SFT 訓練並重現上述結果。</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fdb07589-049d-432e-8001-e6e9175ad806",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afa382a3da24b1f81a856b0cd3aefc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 模型載入完成，使用設備: CPU\n"
     ]
    }
   ],
   "source": [
    "# 下載 HuggingFaceTB/SmolLM2-135M 模型\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# 下載小模型到本地目錄\n",
    "snapshot_download(\n",
    "    repo_id=\"HuggingFaceTB/SmolLM2-135M\",\n",
    "    local_dir=\"./models/HuggingFaceTB/SmolLM2-135M\",\n",
    "    local_dir_use_symlinks=False\n",
    ")\n",
    "\n",
    "# 使用小模型並設定為CPU模式以避免記憶體問題\n",
    "model_name = \"./models/HuggingFaceTB/SmolLM2-135M\"\n",
    "USE_GPU = False  # 改為False以避免記憶體問題\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, USE_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d52c3e-9c6c-43c3-bd95-92d60b9c9a8f",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練資料集範例：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User Prompt</th>\n",
       "      <th>Assistant Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- The left child should have a value less than the parent node's value, and the right child should have a value greater than the parent node's value.</td>\n",
       "      <td>This statement is correct. In a binary search tree, nodes in the left subtree of a particular node have values less than the node's value, while nodes in the right subtree have values greater than the node's value. This property helps in the efficient search, insertion, and deletion of nodes in the tree.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>To pass three levels must be the plan.\\nThen tackle Two, when that is done.\\nOf 100 that start, at the end will be 20.\\nFinQuiz is a website that helps you prepare.\\nUse it to be stress-free, and not lose your hair.\\nThen, take the exam with a smile on your face.\\nBe confident that you will gain your place.\\nSo make this the goal to which you aspire. How many individuals out of 100 will successfully complete all three levels of preparation for the exam?</td>\n",
       "      <td>Based on the given information, out of 100 individuals who start, only 20 will make it to the end. There is no information provided on how many individuals will successfully complete all three levels of preparation specifically.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you translate the text material into Spanish or any other language?: He really is, you know.\\nThings a hero should show.\\nHe loves me more than a zillion things.\\nHe loves me when I sing my jolly folktale rhymes.\\nHe's good, not just good, in fact he's great!\\nBut because he's my best mate!\\nWOW !!! I love it!!!!</td>\n",
       "      <td>¿Puede traducir el texto a español o a cualquier otro idioma?: \\nRealmente lo es, ya sabes.\\nCosas que un héroe debería demostrar.\\nMe quiere más que un millón de cosas.\\nMe quiere cuando canto mis alegres rimas de cuentos populares.\\nEs bueno, no solo bueno, ¡de hecho es genial!\\n¡Pero porque es mi mejor amigo!\\n¡WOW! ¡Me encanta!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                 User Prompt  \\\n",
       "0                                                                                                                                                                                                                                                                                                                      - The left child should have a value less than the parent node's value, and the right child should have a value greater than the parent node's value.   \n",
       "1  To pass three levels must be the plan.\\nThen tackle Two, when that is done.\\nOf 100 that start, at the end will be 20.\\nFinQuiz is a website that helps you prepare.\\nUse it to be stress-free, and not lose your hair.\\nThen, take the exam with a smile on your face.\\nBe confident that you will gain your place.\\nSo make this the goal to which you aspire. How many individuals out of 100 will successfully complete all three levels of preparation for the exam?   \n",
       "2                                                                                                                                             Can you translate the text material into Spanish or any other language?: He really is, you know.\\nThings a hero should show.\\nHe loves me more than a zillion things.\\nHe loves me when I sing my jolly folktale rhymes.\\nHe's good, not just good, in fact he's great!\\nBut because he's my best mate!\\nWOW !!! I love it!!!!   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                              Assistant Response  \n",
       "0                              This statement is correct. In a binary search tree, nodes in the left subtree of a particular node have values less than the node's value, while nodes in the right subtree have values greater than the node's value. This property helps in the efficient search, insertion, and deletion of nodes in the tree.  \n",
       "1                                                                                                           Based on the given information, out of 100 individuals who start, only 20 will make it to the end. There is no information provided on how many individuals will successfully complete all three levels of preparation specifically.  \n",
       "2  ¿Puede traducir el texto a español o a cualquier otro idioma?: \\nRealmente lo es, ya sabes.\\nCosas que un héroe debería demostrar.\\nMe quiere más que un millón de cosas.\\nMe quiere cuando canto mis alegres rimas de cuentos populares.\\nEs bueno, no solo bueno, ¡de hecho es genial!\\n¡Pero porque es mi mejor amigo!\\n¡WOW! ¡Me encanta!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "資料集大小：2000 個樣本\n",
      "\n",
      "資料集特點：\n",
      "- 包含多樣化的指令和回應對\n",
      "- 涵蓋問答、翻譯、計算等多種任務\n",
      "- 每個樣本都包含使用者提示和助手回應\n",
      "- 增加到500個樣本以改善小模型訓練效果\n",
      "- 小模型需要更多樣本才能學到良好的對話模式\n"
     ]
    }
   ],
   "source": [
    "# 載入訓練資料集\n",
    "train_dataset = load_dataset(\"banghua/DL-SFT-Dataset\")[\"train\"]\n",
    "\n",
    "# 增加資料集大小以改善小模型的訓練效果（從100增加到500）\n",
    "train_dataset = train_dataset.select(range(2000))\n",
    "\n",
    "# 顯示資料集的前幾個範例\n",
    "print(\"訓練資料集範例：\")\n",
    "display_dataset(train_dataset)\n",
    "\n",
    "print(f\"\\n資料集大小：{len(train_dataset)} 個樣本\")\n",
    "print(\"\\n資料集特點：\")\n",
    "print(\"- 包含多樣化的指令和回應對\")\n",
    "print(\"- 涵蓋問答、翻譯、計算等多種任務\") \n",
    "print(\"- 每個樣本都包含使用者提示和助手回應\")\n",
    "print(\"- 增加到500個樣本以改善小模型訓練效果\")\n",
    "print(\"- 小模型需要更多樣本才能學到良好的對話模式\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c515a8-3728-45fa-88cc-6eb4de839839",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFT 訓練配置說明（針對小模型優化，修復重複問題）：\n",
      "學習率: 0.0001 - 提高以幫助小模型更快學習\n",
      "訓練輪數: 3 - 增加到3輪，小模型需要更多訓練\n",
      "批次大小: 2 - 稍微增加\n",
      "梯度累積: 4 - 減少以加快更新\n",
      "有效批次大小: 8\n",
      "最大序列長度: 256 - 減少以適應小模型\n",
      "生成: 添加repetition_penalty=1.2和temperature=0.7減少重複\n",
      "正規化: 添加weight_decay和warmup_steps防止過擬合\n"
     ]
    }
   ],
   "source": [
    "# SFT 訓練器配置（針對小模型優化，修復重複問題）\n",
    "sft_config = SFTConfig(\n",
    "    learning_rate=1e-4,  # 提高學習率幫助小模型更快學習\n",
    "    num_train_epochs=3,  # 增加訓練輪數，小模型需要更多訓練\n",
    "    per_device_train_batch_size=2,  # 稍微增加批次大小\n",
    "    gradient_accumulation_steps=4,  # 減少梯度累積步驟\n",
    "    gradient_checkpointing=False,  # 小模型不需要梯度檢查點\n",
    "    logging_steps=50,  # 增加記錄間隔\n",
    "    \n",
    "    # 關鍵修復：添加以下參數來避免重複和改善訓練\n",
    "    max_seq_length=256,  # 減少序列長度以適應小模型\n",
    "    dataset_text_field=\"messages\",  # 指定資料集的文字欄位\n",
    "    packing=False,  # 關閉序列打包，確保訓練穩定\n",
    "    remove_unused_columns=False,  # 保留所有欄位\n",
    "    \n",
    "    # 添加正規化以減少過擬合\n",
    "    weight_decay=0.01,  # 權重衰減\n",
    "    warmup_steps=20,  # 預熱步驟\n",
    "    \n",
    "    # 評估配置\n",
    "    save_steps=100,  # 保存檢查點頻率\n",
    "    eval_steps=50,  # 評估頻率（如果有驗證集）\n",
    ")\n",
    "\n",
    "# 關鍵超參數解釋：\n",
    "print(\"SFT 訓練配置說明（針對小模型優化，修復重複問題）：\")\n",
    "print(f\"學習率: {sft_config.learning_rate} - 提高以幫助小模型更快學習\")\n",
    "print(f\"訓練輪數: {sft_config.num_train_epochs} - 增加到3輪，小模型需要更多訓練\")\n",
    "print(f\"批次大小: {sft_config.per_device_train_batch_size} - 稍微增加\")\n",
    "print(f\"梯度累積: {sft_config.gradient_accumulation_steps} - 減少以加快更新\")\n",
    "print(f\"有效批次大小: {sft_config.per_device_train_batch_size * sft_config.gradient_accumulation_steps}\")\n",
    "print(f\"最大序列長度: {sft_config.max_seq_length} - 減少以適應小模型\")\n",
    "print(\"生成: 添加repetition_penalty=1.2和temperature=0.7減少重複\")\n",
    "print(\"正規化: 添加weight_decay和warmup_steps防止過擬合\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cd7d132-4c69-4b12-a8ec-e6b4795faad9",
   "metadata": {
    "height": 132
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 03:47, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.567900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.522600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.601300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.645800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.680900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.139800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.238400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.223300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.953400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.984900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.914100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.919500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=750, training_loss=1.2521834920247397, metrics={'train_runtime': 228.1798, 'train_samples_per_second': 26.295, 'train_steps_per_second': 3.287, 'total_flos': 727475406605568.0, 'train_loss': 1.2521834920247397})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=train_dataset, \n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "sft_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b4bac1-7262-4c55-b411-6a59188157b0",
   "metadata": {},
   "source": [
    "## 測試小型模型和小資料集的訓練結果\n",
    "\n",
    "**注意：** 以下結果是針對我們在 SFT 訓練中使用的小型模型和資料集，這是由於計算資源有限。若要查看大型模型的完整訓練結果，請參閱上方的 **「Qwen3-0.6B 模型的 SFT 結果」** 部分。\n",
    "\n",
    "### 預期結果分析：\n",
    "由於我們使用的是小型模型（相對較少的參數）和有限的訓練資料，模型的表現可能會有以下特點：\n",
    "- **有一定的改善**：相比未訓練的模型，應該能看到明顯的改善\n",
    "- **仍有限制**：由於模型規模和資料量的限制，可能無法達到完美的表現\n",
    "- **學習能力展現**：可以觀察到模型開始學會回應指令的基本能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d678274-5768-4cea-ae20-051488e5d0f3",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Base Model (After SFT) Output ===\n",
      "\n",
      "Model Input 1:\n",
      "Give me an 1-sentence introduction of LLM.\n",
      "Model Output 1:\n",
      "1. I am a Licensed Marriage and Family Therapist (LFTT).\n",
      "\n",
      "2. My background in counseling, specifically marriage and family therapy has made it easy for me to provide compassionate and effective solutions tailored to individual needs.\n",
      "\n",
      "3. As a result, my work is highly sought after by both mental health professionals and individuals seeking help with various issues related to relationships and emotional wellbeing.\n",
      "\n",
      "4. Through experience as a licensed professional counselor, I have gained valuable insights into the unique challenges faced when\n",
      "\n",
      "\n",
      "Model Input 2:\n",
      "Calculate 1+1-1\n",
      "Model Output 2:\n",
      "3. Subtract the result from step two (step four) to get your answer in decimal form, which is 0.52846...\n",
      "Note that you can round off any calculated number by simply adding or subtracting a predetermined value called a \"decimal point.\" Therefore, if desired precision was requested for this calculation, adjust accordingly!\n",
      "For example: Given our original question:\n",
      "\n",
      "1 + 1 - 1 = 0.5\n",
      "So there's approximately 0.\n",
      "\n",
      "\n",
      "Model Input 3:\n",
      "What's the difference between thread and process?\n",
      "Model Output 3:\n",
      "1. Thread is a single-threaded program that runs concurrently with other threads while processes are run on different computers or operating systems independently of each other, creating multitasking capabilities similar to those found in modern multi-user computing environments such as Windows XP and its successors. Processes can be started by running their own command line interface (CLI) tool like Task Manager or Control Panel to manage them effectively without any coordination from another application or user.\n",
      "\n",
      "2. Threads have an exclusive execution period\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if not USE_GPU: # move model to CPU when GPU isn't requested\n",
    "    sft_trainer.model.to(\"cpu\")\n",
    "test_model_with_questions(sft_trainer.model, tokenizer, questions, \n",
    "                          title=\"Base Model (After SFT) Output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bogag1lqd7",
   "metadata": {},
   "source": [
    "## 課程總結與深入思考\n",
    "\n",
    "### 我們在這個課程中學到了什麼：\n",
    "\n",
    "#### 1. SFT 的核心概念\n",
    "- **定義**：監督式微調（SFT）是一種將基礎語言模型轉換為能夠遵循指令的對話模型的技術\n",
    "- **原理**：通過最小化負對數似然損失函數，讓模型學習模仿訓練資料中的回應\n",
    "- **目標**：使模型能夠理解並適當回應使用者的各種指令和問題\n",
    "\n",
    "#### 2. SFT 的數學基礎\n",
    "- **損失函數**：`Loss = -log P(response | prompt)`\n",
    "- **訓練目標**：最大化給定提示下生成正確回應的概率\n",
    "- **實現方式**：對所有訓練樣本的損失求和並進行梯度下降\n",
    "\n",
    "#### 3. 資料品質的重要性\n",
    "- **品質勝於數量**：1000個高品質樣本往往比100萬個混合品質的樣本效果更好\n",
    "- **資料整理方法**：\n",
    "  - 蒸餾：使用較大模型生成高品質回應\n",
    "  - 最佳 k 選擇：從多個生成結果中選擇最佳回應\n",
    "  - 篩選：根據品質和多樣性篩選大規模資料集\n",
    "\n",
    "#### 4. 實際應用場景\n",
    "- **模型行為啟動**：將預訓練模型轉為指令模型\n",
    "- **能力改善**：提升特定任務的表現\n",
    "- **知識蒸餾**：將大模型的能力轉移到小模型\n",
    "\n",
    "### 深入思考：SFT 訓練難題診斷\n",
    "\n",
    "#### 為何訓練損失並非單調遞減？\n",
    "\n",
    "觀察到訓練過程中損失值變化：\n",
    "```\n",
    "1000    0.604300\n",
    "1050    0.615200  ← 上升\n",
    "1100    0.621700  ← 繼續上升\n",
    "```\n",
    "\n",
    "**原因分析：**\n",
    "1. **學習率過高**：導致在損失函數的最小值附近震盪\n",
    "2. **過擬合開始**：模型開始記憶訓練資料，汎化能力下降\n",
    "3. **批次間變異**：不同批次的資料分佈差異導致損失波動\n",
    "4. **資料品質不一致**：訓練資料中存在品質差異較大的樣本\n",
    "\n",
    "#### 如何判斷 SFT 訓練失敗的根本原因？\n",
    "\n",
    "##### 1. 資料問題診斷指標\n",
    "\n",
    "**量化指標：**\n",
    "- **資料量是否充足**\n",
    "  - 小模型（<1B）：至少需要 10K-50K 高品質樣本\n",
    "  - 中型模型（1B-7B）：需要 100K-500K 樣本\n",
    "  - 大型模型（>7B）：需要 1M+ 樣本\n",
    "\n",
    "- **資料品質評估**\n",
    "  ```python\n",
    "  # 建議的品質檢查指標\n",
    "  - 平均回應長度 vs 預期長度\n",
    "  - 重複樣本比例（<5%）\n",
    "  - 不相關回應比例（<2%）\n",
    "  - 語言錯誤比例（<1%）\n",
    "  ```\n",
    "\n",
    "**診斷方法：**\n",
    "- **人工抽樣評估**：隨機選取 100-200 個樣本進行人工評分\n",
    "- **自動化品質檢查**：使用較大模型評估回應品質\n",
    "- **多樣性分析**：計算指令類型分佈和語義多樣性\n",
    "\n",
    "##### 2. 模型能力極限診斷指標\n",
    "\n",
    "**量化指標：**\n",
    "- **模型容量分析**\n",
    "  ```python\n",
    "  參數量 vs 任務複雜度比例\n",
    "  - 135M 模型：適合簡單問答、基本對話\n",
    "  - 0.6B 模型：適合多輪對話、基本推理\n",
    "  - 7B+ 模型：適合複雜推理、專業知識\n",
    "  ```\n",
    "\n",
    "- **學習曲線分析**\n",
    "  - 訓練損失持續下降但驗證損失停滯 → 過擬合\n",
    "  - 訓練和驗證損失都停滯 → 模型容量不足\n",
    "  - 損失下降但品質不提升 → 評估指標問題\n",
    "\n",
    "**實用診斷流程：**\n",
    "\n",
    "1. **數據診斷優先**（80%的問題來自資料）\n",
    "   ```python\n",
    "   # 快速診斷腳本\n",
    "   def diagnose_data_quality(dataset):\n",
    "       # 檢查重複率\n",
    "       # 檢查平均長度\n",
    "       # 檢查格式一致性\n",
    "       # 人工抽樣評估\n",
    "   ```\n",
    "\n",
    "2. **模型能力測試**\n",
    "   ```python\n",
    "   # 簡單基準測試\n",
    "   simple_tasks = [\n",
    "       \"計算 2+2\",\n",
    "       \"翻譯 'hello' 到中文\", \n",
    "       \"列出3種水果\"\n",
    "   ]\n",
    "   # 如果簡單任務都失敗 → 模型或訓練有根本問題\n",
    "   ```\n",
    "\n",
    "3. **對比基準**\n",
    "   - 同樣模型 + 高品質小資料集 vs 大量混合資料集\n",
    "   - 不同大小模型 + 相同資料集\n",
    "\n",
    "##### 3. 實戰經驗法則\n",
    "\n",
    "**資料問題的信號：**\n",
    "- 模型輸出格式不一致\n",
    "- 經常產生無關回應\n",
    "- 特定類型問題表現極差\n",
    "- 增加資料量後效果顯著提升\n",
    "\n",
    "**模型限制的信號：**\n",
    "- 簡單任務也無法完成\n",
    "- 增加資料量效果不明顯\n",
    "- 更大模型在相同資料上表現明顯更好\n",
    "- 訓練損失下降但實際表現無改善\n",
    "\n",
    "**建議的優化順序：**\n",
    "1. 先優化資料品質（投入產出比最高）\n",
    "2. 調整訓練超參數\n",
    "3. 考慮增加模型大小\n",
    "4. 使用進階技術（如 LoRA、量化等）"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "post-training-llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
